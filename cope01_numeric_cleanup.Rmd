---
title: "cope01 numeric cleanup"
author: "Miki Bálint"
output:
  html_notebook:
    toc: yes
    toc_depth: 3
  html_document:
    theme: united
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: 3
---
\newpage

# Libraries and workdir
```{r message=F}
library(vegan)
library(reshape2)

rm(list=ls())

setwd("~/Documents/Irodalom/Articles/Prepared/Lake_diversity/Analyses/grenoble_experiment/data_cleanup/cope01/")
```

# Assigned read abundances
```{r}
# cope01_obi = read.csv(file="../../../Data/grenoble_experiment/cope01_assigned.tab",
#                       header=T, sep='|', row.names = 1)
# save.image(file = "cope01_obi_input.Rdata")

load(file = "cope01_obi_input.Rdata")
```

# Basic info
Index the samples.

How many reads were assigned to cope01 ecoPCR hits with 85% sequence similarity?
```{r}
# index the samples
index_sample = grep("sample\\.", names(cope01_obi))

sum(cope01_obi[,index_sample])
```

# Diagnostic plots from Fred's suggestions and other filters

## Fred 1. Frequency distribution of read numbers in **OTUs**

This step defines a rarity threshold for **OTUs**

```{r}
reads_per_seq_variant <- apply(cope01_obi[,index_sample],1,sum)
freq_table = data.frame(table(reads_per_seq_variant))
freq_table$reads_per_seq_variant <- 
  as.vector(freq_table$reads_per_seq_variant)
plot(freq_table, log = c("xy"), xlab = c("Read count in seq variant")) +
  abline(v = 50, col="red")
```

A sequence variant with less, than 50 sequences is considered as rare. Rare and frequent sequence variants:
```{r}
index_rare_sequence = apply(cope01_obi[,index_sample],1,sum) >= 50
summary(index_rare_sequence)
```

## Fred 2. Frequency distribution of **replicates**

This defines a rarity threshold for **replicates**.

```{r}
sample_reads <- apply(cope01_obi[,index_sample],2,sum)
hist(sample_reads, nclass = 10000, xlim = c(0,2000), ylim = c(0,50), 
     xlab = c("No. Reads in a replicate"), main = "")
abline(v=100, col="red")
```

There are many replicates with few (below 100) reads. 

```{r}
intervals <- cut(sample_reads, 
                 breaks=seq(from=0, to = 100000, by = 50))
head(table(intervals), 20)
```

Replicates must have min. 100 reads to be considered
```{r}
index_small_replicate = apply(cope01_obi[,index_sample],2,sum) > 99
summary(index_small_replicate)
```

## Fred 3. richness ~ reads
This identifies 
1) the linearly growing phase of the richness - read number relationship. Richness in samples is likely driven only by read numbers in this phase.
2) replicates that have weird richness-read number relationship: these have high read numbers, but strangely low richness that falls outside of the expected distribution.

```{r}
rich_reads = data.frame(
  count = apply(cope01_obi[,index_sample],2,sum),
  rich = specnumber(t(cope01_obi[,index_sample])))

plot(rich_reads, log=c("xy"), pch = ".") +
  abline(v=100, col = "red") +
  abline(h=5, col = "red")
```


Replicates that show weird richness ~ read count relationships:
relatively high read count in a sample but low richness
(the lower left square)

```{r}
index_weird_replicate <- rich_reads$rich < 5 & rich_reads$count > 100
# index selects non-weird samples
index_weird_replicate <- !index_weird_replicate
summary(index_weird_replicate)
# rich_reads[index_weird_replicate,]
```

## Replicate filters combined
```{r}
index_replicate_combined <- index_small_replicate & index_weird_replicate
```

## Head-singlteon-internal filter
```{r}
index_head <- (cope01_obi$obiclean_headcount + cope01_obi$obiclean_singletoncount) > 
  cope01_obi$obiclean_internalcount

```

## Combined OTU filter
```{r}
index_seq_combined = index_rare_sequence & index_head
```


# Filter out rare OTUs and internal OTUs.
Reads lost with these OTUs: < 20%
```{r}
cope01_replicates <- cope01_obi[index_seq_combined,index_sample]
sum(cope01_replicates)
```

# Controls

## Negative controls

### Extraction controls
```{r}
EXC = grep("sample.EXT", names(cope01_replicates))
```

### PCR controls
```{r}
PNC = grep("sample.PNC", names(cope01_replicates))
```

### Multiplexing controls
```{r}
MPC = grep("sample.MPC", names(cope01_replicates))
```

### Clean abundance matrix of contamination from negative controls
Most sequence variants rarely have many reads in the negatives
```{r}
max_in_negative <- apply(cope01_replicates[,c(EXC,PNC,MPC)], 1, max)
head(table(max_in_negative), 20)
```

Sweep the maximum counts of an OTU in any negative control from all observations.
Set negative values to 0. Further ~15% of reads removed with this step.
```{r}
cope01_neg_controlled <- cope01_replicates
cope01_neg_controlled <- sweep(cope01_neg_controlled, 1, max_in_negative, "-")
cope01_neg_controlled[cope01_neg_controlled < 0] <- 0
sum(cope01_neg_controlled)
```


## Positive controls
```{r}
POC = grep("sample.POC", names(cope01_neg_controlled))
```

Sums of overall reads/OTU, and POC reads/OTU
```{r}
mean_all_reads = apply(cope01_neg_controlled, 1, mean)
mean_POC_reads = apply(cope01_neg_controlled[,POC], 1, mean)
max_all_reads = apply(cope01_neg_controlled, 1, max)
max_POC_reads = apply(cope01_neg_controlled[,POC], 1, max)
```

Data frame with overall, and POC mean and summed read abundances
```{r}
positive_abundances <- cbind(scientific_name = 
                               cope01_obi$scientific_name[
                                 rownames(cope01_obi) %in%
                                   rownames(cope01_neg_controlled)],
                             mean_all_reads = mean_all_reads,
                             mean_POC_reads = mean_POC_reads,
                             max_all_reads = max_all_reads,
                             max_POC_reads = max_POC_reads,
                             cope01_neg_controlled[,POC])
```

Aggregate positive OTU reads by taxon
```{r}
positive_aggregate = aggregate(. ~ scientific_name, 
                               positive_abundances, 
                               sum, na.action = na.exclude)
```


List the overall, and positive control summed abundances, sorted by mean positives
```{r include=F}
head(format(positive_aggregate[order(-positive_aggregate$mean_POC_reads),1:5],
            scientific=FALSE))
```


Organisms in the positive control and likely corresponding taxa in the sequence variants

|in positive | what | corresponding assignment|
-------------|------|-------------------------|
|Lasallia pustulata | lichen alga ||
|Lasallia pustulata | lichen fungus ||
|Micropterna_P1331 | caddisfly ||
|Fung_P2548 | fungus ||
|Fung_P2135 | fungus ||
|Fung_P2670 | fungus ||
|Fung_P2569 | fungus ||
|Fung_P2638 | fungus ||
|Ponticola kessleri | fish | Gymnothorax, Teleostei, Gobiidae|
|Coregonus sp | fish | Gymnothorax, Teleostei, Gobiidae|
|Pacifastacus leniusculus | crayfish | Pacifastacus leniusculus trowbridgii|
|Aspius aspius | fish | Gymnothorax, Teleostei, Gobiidae|
|Triturus sp. | amphibian | Lissotriton vulgaris, Bufo, Caudata|
|Sphagnum sp. | moss ||
|Linum dolomiticum | plant ||
|Bhytinella | snail ||
|Spalax | mammal ||
|Vipera ursinii rakosiensis | snake ||
|Chironomus sp. | insect | Chironomus tepperi|
|Phragmites sp. | plant ||
|Picea abies | plant ||
|Arion sp. | snail ||

The criterium for positive control amplification is if the mean_POC_reads are higher than the mean_all_reads. This is after Caudata (mean_all_reads=1.31965066, mean_POC_reads=62.93750000). Threshold is then 70

```{r}
cope01_pos_controlled <- cope01_neg_controlled
cope01_pos_controlled[cope01_pos_controlled < 70] <- 0
```

Purge the replicates from potential positive control cross-contaminations
```{r}
max_in_positive <- apply(cope01_pos_controlled[,POC], 1, max)
```

Sweep the maximum counts of an OTU in any positive control from all observations  
```{r}
cope01_pos_controlled <- sweep(cope01_pos_controlled, 1, max_in_positive, "-")
```

Set negative values to 0. 
```{r}
cope01_pos_controlled[cope01_pos_controlled < 0] <- 0
```

## Remove low-abundance and weird replicates
```{r}
# weird replicates
cope01_pos_controlled <- cope01_pos_controlled[,index_replicate_combined]
```

## Delete controls
```{r}
# new control indices
EXC2 = grep("sample.EXT", names(cope01_pos_controlled))
PNC2 = grep("sample.PNC", names(cope01_pos_controlled))
MPC2 = grep("sample.MPC", names(cope01_pos_controlled))
POC2 = grep("sample.POC", names(cope01_pos_controlled))

control_filter <- names(cope01_pos_controlled) %in%
  names(cope01_pos_controlled[,c(EXC2,PNC2,MPC2,POC2)])

cope01_pos_controlled <- cope01_pos_controlled[,!control_filter]
```

## Correct replicate names

Delete the replicates of WM.250A, WM.250B. Note lost why the 250 mm layer of WM is doubled.
```{r}
cope01_final_replicates <- cope01_pos_controlled
index_WM.250A_WM.250B <- 
  grep("WM.250", names(cope01_final_replicates))
filter_WM.250A_WM.250B <- names(cope01_final_replicates) %in%
  names(cope01_final_replicates[,index_WM.250A_WM.250B])
cope01_final_replicates <- 
  cope01_final_replicates[,!filter_WM.250A_WM.250B]
```

Correct FM3 -> FH3, PL40 -> PL1
```{r}
# Names object
names_cope01 <- names(cope01_final_replicates)

# index for FM3, PL40, WM
index_FM3 <- grep("FM3", names_cope01)
index_PL40 <- grep("PL40", names_cope01)

# substitute wrong names
names_cope01 <- gsub("FM3", "FH3", names_cope01)
names_cope01 <- gsub("PL40", "PL1", names_cope01)
names(cope01_final_replicates) <- names_cope01
```

<!-- # False negative model chunk, Diana -->
# Occupancy models data preparation

```{r include = F}
#libraries we will need
library(plyr)
library(ggplot2)
library(reshape2)
library(unmarked)
library(boot)
```

## Prepare data for occupancy
```{r}
#get data files
mydata<-cope01_final_replicates
mydata <- data.frame(X = rownames(cope01_final_replicates),
                     cope01_final_replicates)

# #melt the data frame. very long, load the data instead
# mydata<-melt(mydata,id="X")
# names(mydata)<-c("OTU","Sample","Count")
# 
# #separate the sample columns
# mydata$Rep<-sapply(as.character(mydata$Sample),function(x)strsplit(x,"_")[[1]][2])
# mydata$Lake<-sapply(as.character(mydata$Sample),function(x)strsplit(x,"\\.")[[1]][2])
# mydata$Depth<-sapply(as.character(mydata$Sample),function(x)strsplit(x,"\\.")[[1]][3])
# mydata$Depth<-as.numeric(sapply(mydata$Depth,function(x)strsplit(x,"_")[[1]][1]))
# 
# save.image(file = "cope01_ocupancy_input.Rdata")

load(file = "cope01_ocupancy_input.Rdata")
tail(mydata)
```

## Remove OTU seen less than twice
```{r}
#summary statistics of the OTUs
sumStats<-ddply(mydata,.(OTU),summarise,
                nu=length(Count[Count>0&!is.na(Count)]))
sumStats
mydata<-subset(mydata,!mydata$OTU%in%sumStats$OTU[sumStats$nu<=6])
```

## OTU metadata

### Select relevant metadata

Select OTU descriptors from obi file
```{r include=FALSE}
cope01_otu_clean_obi <- 
  cope01_obi[levels(factor(mydata$OTU)),]

cope01_otu_clean_meta <- data.frame()
cope01_otu_clean_meta <- 
  data.frame(def = cope01_otu_clean_obi$definition,
             best_id_cope01 = 
               cope01_otu_clean_obi$best_identity.db_cope01,
             best_match = cope01_otu_clean_obi$best_match,
             count = cope01_otu_clean_obi$count,
             family_name = cope01_otu_clean_obi$family_name,
             genus_name = cope01_otu_clean_obi$genus_name,
             rank = cope01_otu_clean_obi$rank,
             sci_name = cope01_otu_clean_obi$scientific_name,
             species_name = cope01_otu_clean_obi$species_name,
             taxid = cope01_otu_clean_obi$taxid,
             sequence = cope01_otu_clean_obi$sequence,
             OTU = rownames(cope01_otu_clean_obi))
head(cope01_otu_clean_meta,2)
```

Add crustacean filter to OTU metadata
```{r}
names(cope01_otu_clean_meta)
levels(factor(cope01_otu_clean_meta$sci_name))

crustacean <- c("Cladocera", "Crustacea", "Daphnia", "Daphnia pulex",
                "Daphniidae", "Diaptomidae", "Diaptomus cyaneus",
                "Pancrustacea", "Fabaeformiscandona kushiroensis")

cope01_otu_clean_meta <- 
  data.frame(cope01_otu_clean_meta,
             crustacean = 
               cope01_otu_clean_meta$sci_name %in% crustacean)
```

Add order names
```{r include = F}
library(tidyverse)
```

```{r}
cope01_otu_clean_meta$def %>%
  stringr::str_split("name=", simplify = T) -> 
  cope1_order_names

cope1_order_names[,2] %>%
  stringr::str_split(";", simplify = T) -> 
  cope1_order_names

cope01_otu_clean_meta <- 
  data.frame(cope01_otu_clean_meta,
             order = cope1_order_names[,1])

cope01_otu_clean_meta[c(3:5),]
```

### Crustacean OTU metadata
```{r}
crustacean_otu_meta <- 
  filter(cope01_otu_clean_meta, crustacean == TRUE)
```

## Crustacean OTU abundances
```{r}
mydata_crustacean <- 
  subset(mydata, mydata$OTU %in% crustacean_otu_meta$OTU)
```

Attach OTU metadata to longformat abundances
```{r}
# View(right_join(mydata, crustacean_otu_meta,
                         # by = "OTU"))
```

## Plotting the data
```{r fig.asp=1.3}
ggplot(data=mydata_crustacean,
       aes(x=Depth,y=Count))+
  scale_y_log10()+
  geom_point(aes(colour=Rep))+
  facet_grid(OTU~Lake)
```

## Fit site-occupancy model 

### Format data for unmarked

For simplicity combine data across lakes
```{r}
mydata_crustacean_combined <-
  ddply(mydata_crustacean,
        .(OTU,Depth,Rep),
        summarise,
        Count=sum(Count))
```

Using only presence/absence data
```{r}
mydata_crustacean_combined$Count <- 
  ifelse(mydata_crustacean_combined$Count>0,1,0)
```

### Fit combined lake model species by species and estimate detection and occupancy at each depth

```{r}
mydataAll<-ddply(mydata_crustacean_combined,
                 .(OTU),
                 function(x){
  
  #reformatting for the package
  mydataD<-dcast(x,Depth~Rep,value.var="Count")
  y = mydataD[,c("A","B","C","D","E","F")]
  siteCovs = data.frame(Depth=mydataD[,"Depth"])
  obsCovs =  list(depth=mydataD[,c("Depth","Depth","Depth","Depth","Depth","Depth")])
  
  #define the dataframe for the package
  wt <- unmarkedFrameOccu(y = y, siteCovs = siteCovs, obsCovs =  obsCovs)
  
  #using pcount
  ## Two models: Detection covariates follow first tilde, then Osccupancy covariates are second
  fm1 <- occu(~depth ~Depth, data=wt)
  
  #take the fitted relationship of detectability with with depth
  my_intercept<-as.numeric(fm1@estimates@estimates$det@estimates[1])
  my_slope<-as.numeric(fm1@estimates@estimates$det@estimates[2])
  x$predictedDetection<-inv.logit(my_intercept+my_slope*x$Depth)
  
  #get predicted occupancy with depth
  my_intercept<-as.numeric(fm1@estimates@estimates$state@estimates[1])
  my_slope<-as.numeric(fm1@estimates@estimates$state@estimates[2])
  x$predictedOccupancy<-inv.logit(my_intercept+my_slope*x$Depth)
  
  return(x)
})
```

#### Plot depth-dependent detection and occupancy

Relationship between depth and detection
```{r}
qplot(Depth,predictedDetection,data=mydataAll,colour=OTU)+
  theme(legend.position="none")
```

Relationship between depth and occupancy
```{r}
qplot(Depth,predictedOccupancy,data=mydataAll,colour=OTU)+
  theme(legend.position="none")
```

### Fit single lake model species by species and estimate detection and occupancy at each depth

```{r}
  #reformatting for the package
  mydataD_lake<-dcast(mydata_crustacean,
                      Depth + Lake ~ Rep,
                      value.var="Count")

  y = mydataD_lake[,c("A","B","C","D","E","F")]
  siteCovs = data.frame(Depth = mydataD_lake[,"Depth"], 
                        Lake = mydataD_lake[,"Lake"])
  obsCovs =  list(depth=mydataD_lake[,c("Depth","Depth",
                                      "Depth","Depth",
                                      "Depth","Depth")])
  
  #define the dataframe for the package
  wt <- unmarkedFrameOccu(y = y, 
                          siteCovs = siteCovs, 
                          obsCovs =  obsCovs)
  
  #using pcount
  ## Two models: Detection covariates follow first tilde, then Osccupancy covariates are second
  fm1_lake <- occu(~depth ~Depth + Lake, data=wt)
  
  #take the fitted relationship of detectability with with depth
  my_intercept_lake <- 
    as.numeric(fm1_lake@estimates@estimates$det@estimates[1])
  my_slope_lake <- 
    as.numeric(fm1_lake@estimates@estimates$det@estimates[2])
  mydata_crustacean$predictedDetection <-
    inv.logit(my_intercept_lake+my_slope_lake*mydata_crustacean$Depth)
  
  #get predicted occupancy with depth
  my_intercept_lake <-
    as.numeric(fm1_lake@estimates@estimates$state@estimates[1])
  my_slope_lake<-as.numeric(fm1_lake@estimates@estimates$state@estimates[2])
  mydata_crustacean$predictedOccupancy<-inv.logit(my_intercept_lake+my_slope_lake*mydata_crustacean$Depth)
```

#### Plot each lake detection and occupancy

Relationship between depth and detection
```{r}
qqplot(data = mydata_crustacean,
       aes(x = Depth, y = predictedDetection)) +
  geom_point(aes(color = OTU))

+
  facet_grid(OTU~Lake)


qplot(Depth,predictedDetection,data=mydata_crustacean,colour=OTU)+
  theme(legend.position="none")
```

Relationship between depth and occupancy
```{r}
qplot(Depth,predictedOccupancy,data=mydataAll,colour=OTU)+
  theme(legend.position="none")
```

## Occupancy models in each lake
# Subset data for each lake
mydata_crustacean

# Environmental data
```{r include=F}
library(imputeTS)
```

Read the environmental data
```{r}
input <- read.csv(file="~/Documents/Irodalom/Articles/Prepared/Lake_diversity/Analyses/Data/multiproxy/lake_data_lakes-combined_170920 - Sheet1.csv", 
                  header = T, na.strings=c(""," ","NA"))

# correct the WM1.250 to WM1.250B
# input$dna <- gsub("WM1.250", "WM1.250B", input$dna)
```

Interpolate NAs
```{r include = F}
inter <- data.frame()
for (i in levels(input$code)){
  actual <- input[input$code == i,]
  actual_inter <- na.interpolation(actual[,18:53])
  inter <- bind_rows(inter, actual_inter)
}
inter <- bind_cols(input[,1:17], inter)
rownames(inter) <- rownames(input)
rm(list = c("actual", "actual_inter", "i"))
```

<!-- Check if all eDNA horizons are in the environmental data. There are no measurements for CR yet. -->
<!-- ```{r} -->
<!-- names(cope01_clean)[!(names(cope01_clean) %in% input$dna)] -->
<!-- ``` -->

<!-- Correct the wrong horizon names "FH3.90", "PL1.50", check again -->
<!-- ```{r} -->
<!-- names(cope01_clean) <- gsub("\\<FH3.90\\>", "FH3.090", names(cope01_clean)) -->
<!-- names(cope01_clean) <- gsub("\\<PL1.50\\>", 'PL1.050', names(cope01_clean)) -->
<!-- names(cope01_clean)[!(names(cope01_clean) %in% input$dna)] -->
<!-- ``` -->


```{r}
#################################################################################

#fitting as site-occupancy model 

#for simplicity combine data across lakes
mydata<-ddply(mydata,.(OTU,Depth,Rep),summarise,Count=sum(Count))

#using only presence/absence data
mydata$Count<-ifelse(mydata$Count>0,1,0)

##############################################################################
#analyse species by species and estimate detetion and occupancy at each depth#
##############################################################################

mydataAll<-ddply(mydata,.(OTU),function(x){
  
  #reformatting for the package
  mydataD<-dcast(x,Depth~Rep,value.var="Count")
  y = mydataD[,c("A","B","C","D","E","F")]
  siteCovs = data.frame(Depth=mydataD[,"Depth"])
  obsCovs =  list(depth=mydataD[,c("Depth","Depth","Depth","Depth","Depth","Depth")])
  
  #define the dataframe for the package
  wt <- unmarkedFrameOccu(y = y, siteCovs = siteCovs, obsCovs =  obsCovs)
  
  #using pcount
  ## Two models: Detection covariates follow first tilde, then Osccupancy covariates are second
  fm1 <- occu(~depth ~Depth, data=wt)
  
  #take the fitted relationship of detectability with with depth
  my_intercept<-as.numeric(fm1@estimates@estimates$det@estimates[1])
  my_slope<-as.numeric(fm1@estimates@estimates$det@estimates[2])
  x$predictedDetection<-inv.logit(my_intercept+my_slope*x$Depth)
  
  #get predicted occupancy with depth
  my_intercept<-as.numeric(fm1@estimates@estimates$state@estimates[1])
  my_slope<-as.numeric(fm1@estimates@estimates$state@estimates[2])
  x$predictedOccupancy<-inv.logit(my_intercept+my_slope*x$Depth)
  
  return(x)
})

#relationship between depth and detection
qplot(Depth,predictedDetection,data=mydataAll,colour=OTU)+
  theme(legend.position="none")

#relationship between depth and occupancy
qplot(Depth,predictedOccupancy,data=mydataAll,colour=OTU)+
  theme(legend.position="none")
```




<!-- Send replicate data to Diana for occupancy models -->
<!-- ```{r} -->
<!-- cope01_pres_abs <- cope01_pos_controlled -->
<!-- cope01_pres_abs[cope01_pres_abs > 0] <- 1 -->

<!-- ar <- grep("AR", names(cope01_to_diana)) -->
<!-- names(cope01_to_diana)[ar] -->
<!-- bl <- grep("BL", names(cope01_to_diana)) -->
<!-- names(cope01_to_diana)[bl] -->
<!-- fh <- grep("FH", names(cope01_to_diana)) -->
<!-- names(cope01_to_diana)[fh] -->
<!-- st <- grep("ST", names(cope01_to_diana)) -->
<!-- names(cope01_to_diana)[st] -->
<!-- sl <- grep("SL", names(cope01_to_diana)) -->
<!-- names(cope01_to_diana)[sl] -->

<!-- lakes_to_diana <- c(ar,bl,fh,st,sl) -->

<!-- cope01_to_diana <- cope01_pos_controlled -->
<!-- cope01_to_diana <- cope01_to_diana[ -->
<!--   apply(cope01_pres_abs,1,sum) > 20,lakes_to_diana] -->

<!-- names(cope01_to_diana) <- -->
<!--   sapply(names(cope01_to_diana), -->
<!--          function(x)strsplit(x,"sample\\.")[[1]][2]) -->

<!-- # write.csv(file = "cope01_occupancy_models.csv", cope01_to_diana) -->
<!-- ``` -->
<!-- # False positive control -->

<!-- OTUs observations in horizons with less than two replicate observations are set to zero as potential false positives. Ficetola et al. 2015 shows that this simple threshold deals well with most false positives. -->

<!-- Names of horizon samples -->
<!-- ```{r} -->
<!-- cope01_sample_names = -->
<!--   levels(as.factor(sapply( -->
<!--     strsplit(names(cope01_pos_controlled), -->
<!--              split='_', fixed=TRUE), -->
<!--     function(x) (x[1])))) -->
<!-- ``` -->

<!-- Calculate the average reads of OTUs per horizon, by averaging the reads in replicates, and then multiplying them back by the number of replicates (to have integers) -->
<!-- ```{r} -->
<!-- cope01_sample_means <-  -->
<!--   data.frame(row.names = -->
<!--                rownames(cope01_pos_controlled)) -->
<!-- # average OTU reads in horizons -->
<!-- for (i in 1:length(cope01_sample_names)){ -->
<!--     ActualSet = grep(cope01_sample_names[i], # select the replicates of a horizon  -->
<!--                    names(cope01_pos_controlled)) -->
<!--     cope01_sample_means =  -->
<!--       cbind(cope01_sample_means, -->
<!--             apply(cope01_pos_controlled[ActualSet], 1, mean)* -->
<!--               length(ActualSet)) # multiply with no. of replicates from the horizon -->
<!-- } -->
<!-- colnames(cope01_sample_means) = cope01_sample_names -->
<!-- ``` -->

<!-- Count the OTU presences in horizon replicates -->
<!-- ```{r} -->
<!-- library(vegan) -->
<!-- # OTU presence-absence matrix -->
<!-- cope01_pres_abs <- cope01_pos_controlled -->
<!-- cope01_pres_abs[cope01_pres_abs > 0] <- 1 -->

<!-- # sum presences per horizon -->
<!-- cope01_otu_count_per_horizon <-  -->
<!--   data.frame(row.names =  -->
<!--                rownames(cope01_pres_abs)) -->
<!-- # count the occurence of OTUs in horizon replicates -->
<!-- for (i in 1:length(cope01_sample_names)){ -->
<!--   ActualSet = grep(cope01_sample_names[i], # select the replicates of a horizon  -->
<!--                    names(cope01_pres_abs)) -->
<!--   cope01_otu_count_per_horizon =  -->
<!--     cbind(cope01_otu_count_per_horizon,  -->
<!--           specnumber(cope01_pres_abs[ActualSet])) -->
<!-- } -->
<!-- colnames(cope01_otu_count_per_horizon) = cope01_sample_names -->
<!-- ``` -->

<!-- Set OTU counts to zero in a horizon where the OTU was observed only in a single replicate -->
<!-- ```{r} -->
<!-- # Create a filter for OTU observations in horizon replicates -->
<!-- cope01_over_one_replicate <- cope01_otu_count_per_horizon -->
<!-- cope01_over_one_replicate[cope01_over_one_replicate < 2] <- 0 -->
<!-- cope01_over_one_replicate[cope01_over_one_replicate > 0] <- 1 -->

<!-- # multiply the read count horizon matrix with this simple "filter" -->
<!-- # this removes horizons that have 0 (less than 2 replicates with the OTU, see above) -->
<!-- cope01_false_positive_controlled <- cope01_sample_means*cope01_over_one_replicate -->
<!-- ``` -->
<!-- Finished 170909 -->
<!-- \newpage -->

<!-- Remove empty OTUs, controls -->
<!-- ```{r} -->
<!-- cope01_clean <- cope01_false_positive_controlled -->

<!-- # OTUs that lost all reads -->
<!-- cope01_clean <- cope01_clean[apply(cope01_clean,1,sum) > 0,] -->

<!-- # horizons with no reads. This removes the negative and positive controls  -->
<!-- # those were swept for their reads in the control step -->
<!-- cope01_clean <- cope01_clean[,apply(cope01_clean,2,sum) > 0] -->
<!-- ``` -->

<!-- # Check the data -->
<!-- Check replicate names with Diana's script -->

<!-- ```{r} -->
<!-- cope01_clean_names <- rownames(cope01_clean) -->

<!-- # melt into deep format -->
<!-- cope01_melt  <- melt(data.frame(cope01_clean,X=cope01_clean_names),id="X") -->
<!-- names(cope01_melt)<-c("OTU","Sample","Count") -->

<!-- # separate the sample columns -->
<!-- cope01_melt$Rep<-sapply(as.character(cope01_melt$Sample), -->
<!--                         function(x)strsplit(x,"_")[[1]][2]) -->

<!-- cope01_melt$Lake<-sapply(as.character(cope01_melt$Sample), -->
<!--                          function(x)strsplit(x,"\\.")[[1]][2]) -->

<!-- cope01_melt$Depth<-sapply(as.character(cope01_melt$Sample), -->
<!--                           function(x)strsplit(x,"\\.")[[1]][3]) -->

<!-- # what are the core names? -->
<!-- levels(as.factor(cope01_melt$Lake)) -->
<!-- ``` -->

<!-- Correct FM3 -> FH3, PL40 -> PL1, WM -> WM1 -->

<!-- ```{r} -->
<!-- # Names object -->
<!-- names_cope01 <- names(cope01_clean) -->

<!-- # index for controls -->
<!-- index_FM3 <- grep("FM3", names_cope01) -->
<!-- index_PL40 <- grep("PL40", names_cope01) -->
<!-- index_WM <- grep("WM\\.", names_cope01) -->

<!-- # substitute wrong names -->
<!-- names_cope01 <- gsub("FM3", "FH3", names_cope01) -->
<!-- names_cope01 <- gsub("PL40", "PL1", names_cope01) -->
<!-- names_cope01 <- gsub("WM\\.", "WM1.", names_cope01) -->
<!-- names(cope01_clean) <- names_cope01 -->
<!-- ``` -->

<!-- Check again -->
<!-- ```{r} -->
<!-- cope01_melt2  <- melt(data.frame(cope01_clean,X=cope01_clean_names),id="X") -->

<!-- names(cope01_melt2)<-c("OTU","Sample","Count") -->

<!-- cope01_melt2$Rep<-sapply(as.character(cope01_melt2$Sample), -->
<!--                          function(x)strsplit(x,"_")[[1]][2]) -->

<!-- cope01_melt2$Lake<-sapply(as.character(cope01_melt2$Sample), -->
<!--                           function(x)strsplit(x,"\\.")[[1]][2]) -->

<!-- cope01_melt2$Depth<-sapply(as.character(cope01_melt2$Sample), -->
<!--                            function(x)strsplit(x,"\\.")[[1]][3]) -->

<!-- levels(as.factor(cope01_melt2$Lake)) -->
<!-- ``` -->

<!-- This is the OTU abundance matrix for cope01, with nice horizon names (no "sample.") -->
<!-- ```{r} -->
<!-- names(cope01_clean) <-  -->
<!--   sapply(names(cope01_clean),function(x)strsplit(x,"sample\\.")[[1]][2]) -->

<!-- c(head(names(cope01_clean)), tail(names(cope01_clean))) -->
<!-- ``` -->
<!-- Finished 170909 -->
<!-- \newpage -->





<!-- eddig: 170916 -->

<!-- # Descriptive analyses, code from Diana -->

<!-- Libraries -->
<!-- ```{r include=F} -->
<!-- library(GGally) -->
<!-- library(corrplot) -->
<!-- library(INLA) -->
<!-- library(reshape2) -->
<!-- ``` -->

<!-- ## Prepare the data -->
<!-- ```{r} -->
<!-- cope01_clean_to_melt <- t(cope01_clean) -->
<!-- cope01_clean_to_melt <- data.frame(X = rownames(cope01_clean_to_melt), -->
<!--                                    cope01_clean_to_melt) -->
<!-- cope01_clean_long <- melt(cope01_clean_to_melt, id="X") -->
<!-- names(cope01_clean_long)<-c("dna","otu_name","Count") -->
<!-- ``` -->

<!-- Correct the OTU names: dots to columns -->
<!-- ```{r include = F} -->
<!-- cope01_clean_long$otu_name <- gsub("\\.", "\\:", cope01_clean_long$otu_name) -->
<!-- ``` -->


<!-- Combine otu abundance, horizon environmental, and OTU data -->
<!-- ```{r include = F} -->
<!-- cope01_clean_long %>% -->
<!--   right_join(select(inter, -->
<!--                     lake:lon,  -->
<!--                     date_final:date_trusted, LoI:Zn),  -->
<!--              by = "dna") %>% -->
<!--   right_join(cope01_otu_clean_meta, -->
<!--              by = "otu_name") -> -->
<!--   cope01_clean_long -->
<!-- ``` -->

<!-- ## Plots of OTUs -->

<!-- Lakes: [1] "Arendsee"           "Breiter Luzin"      "Feldberger Haussee" "Oberückersee"       -->
<!-- [5] "Scharmützelsee"     "Schmaler Luzin"     "Stechlin"           "Tiefwarensee"       -->
<!-- [9] "Wummsee"  -->

<!-- Vertical black lines shows the oldest trusted date for a sediment horizon. The size of points is proportional of how much the OTU assignment is trusted: min = 0.85, max = 1, over a fragment length of mean 112 bp. -->

<!-- ```{r} -->
<!-- ggplot_list <- list() -->
<!-- for (i in levels(factor(cope01_clean_long$lake))){ -->
<!--   actual_lake_data <- filter(cope01_clean_long,  -->
<!--                                    lake == i, -->
<!--                                    Count > 0,  -->
<!--                                    crustacean == TRUE, -->
<!--                                    date_trusted == "yes") -->
<!--   min_actual_date <- filter(inter, lake == i, date_trusted == "yes") %>% -->
<!--     select(date_final) %>% -->
<!--     {min(.)} -->
<!--   g_actual <- ggplot(actual_lake_data, -->
<!--                      aes(x = date_final,  -->
<!--                          y = Count, -->
<!--                          group = otu_name)) + -->
<!--   geom_point(aes(colour=otu_name, size = best_id_cope01)) + -->
<!--   geom_line(aes(colour=otu_name)) +  -->
<!--   scale_y_log10() + -->
<!--   xlim(1850, 2016) +  -->
<!--   theme(legend.position="none") + -->
<!--   facet_wrap(nrow = 2, ~sci_name) + -->
<!--   ggtitle(i) -->
<!-- g_actual <- g_actual + geom_vline(xintercept = min_actual_date) -->
<!-- ggplot_list[[i]] <- g_actual -->
<!-- } -->
<!-- ``` -->

<!-- ```{r message=F} -->
<!-- ggplot_list[1] -->
<!-- ggplot_list[2] -->
<!-- ggplot_list[3] -->
<!-- ggplot_list[4] -->
<!-- ggplot_list[5] -->
<!-- ggplot_list[6] -->
<!-- ggplot_list[7] -->
<!-- ggplot_list[8] -->
<!-- ggplot_list[9] -->
<!-- ``` -->

<!-- ## Diversity plots -->

<!-- Hill diversities for all cope01-amplified OTUs -->
<!-- ```{r} -->
<!-- cope01_hill <- renyi(t(cope01_clean),  -->
<!--                        scales = c(0,1,2), -->
<!--                        hill = TRUE) -->

<!-- names(cope01_hill) <- c("cope01_hill_1",  -->
<!--                         "cope01_hill_2",  -->
<!--                         "cope01_hill_3") -->

<!-- cope01_hill <- data.frame(cope01_hill,  -->
<!--                           dna = rownames(cope01_hill)) -->

<!-- melt(cope01_hill, by="dna") %>% -->
<!--   magrittr::set_colnames(c("dna", "cope01_hills",  -->
<!--                            "cope01_hill_values")) -> -->
<!--   cope01_hill_long -->
<!-- ``` -->

<!-- Hill diversities for crustaceans only -->
<!-- ```{r} -->
<!-- filter(cope01_otu_clean_meta, crustacean == TRUE) %>% -->
<!--   select(otu_name) ->  -->
<!--   crustacean_otu -->

<!-- crustacean_filter <- rownames(cope01_clean) %in% -->
<!--   as.character(unlist(crustacean_otu)) -->

<!-- cope01_clean[crustacean_filter,] %>% -->
<!--   t() %>% -->
<!--   renyi(scales = c(0,1,2), hill = TRUE) %>% -->
<!--   magrittr::set_colnames(c("crustacean_hill_1",  -->
<!--                            "crustacean_hill_2", -->
<!--                            "crustacean_hill_3")) %>% -->
<!--   rownames_to_column(var = "dna") %>% -->
<!--   melt(by="dna") %>% -->
<!--   magrittr::set_colnames(c("dna", "crustacean_hills",  -->
<!--                            "crustacean_hill_values")) -> -->
<!--   crustacean_hill_long -->
<!-- ``` -->


<!-- Join diversities to long-form cope01 data -->
<!-- ```{r} -->
<!-- cope01_clean_long %>% -->
<!--   right_join(cope01_hill_long, by = "dna") %>%  -->
<!--   right_join(crustacean_hill_long, by = "dna") -> -->
<!--   cope01_clean_long -->

<!-- # remove the Carwitzer See (NA's for all variables except hill) -->
<!-- cope01_clean_long <- filter(cope01_clean_long, lake != "NA") -->
<!-- ``` -->
<!-- \newpage -->

<!-- Plot the general cope01 diversities. Includes chironomids, ducks, many not assigned organimsm.  -->

<!-- hill_1: species richness -->

<!-- hill_2: exponent of Shannon -->

<!-- hill_3: inverse of Simpson -->

<!-- ```{r fig.asp=1, warning=F, message=F} -->
<!-- g_cope01_div <- ggplot(data = cope01_clean_long,  -->
<!--                        aes(x = date_final, -->
<!--                            y = cope01_hill_values)) + -->
<!--   geom_point(aes(colour=cope01_hills)) + -->
<!--   geom_smooth(aes(colour = cope01_hills)) + -->
<!--   # geom_line(aes(colour=hills)) +  -->
<!--   xlim(1850, 2016) +  -->
<!--   facet_wrap(nrow = 3, ~lake) -->
<!--   # facet_grid(lake~hills, scales = "free_y") -->

<!-- g_cope01_div +  -->
<!--   theme(legend.position = "bottom") + -->
<!--   ggtitle("Diversities of all OTUs amplified with cope01") -->
<!-- ``` -->

<!-- \newpage -->


<!-- Plot the crustacean diversities -->
<!-- ```{r fig.asp=1, warning=F, message=F} -->
<!-- g_crustacean_div <- ggplot(data = cope01_clean_long,  -->
<!--                        aes(x = date_final, -->
<!--                            y = crustacean_hill_values)) + -->
<!--   geom_point(aes(colour=crustacean_hills)) + -->
<!--   geom_smooth(aes(colour = crustacean_hills)) + -->
<!--   # geom_line(aes(colour=hills)) +  -->
<!--   xlim(1850, 2016) +  -->
<!--   facet_wrap(nrow = 3, ~lake) -->
<!--   # facet_grid(lake~hills, scales = "free_y") -->

<!-- g_crustacean_div +  -->
<!--   theme(legend.position = "bottom") + -->
<!--   ggtitle("Diversities of crustaceans") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- save.image(file = -->
<!--              "cope01_finished_numeric_cleanup.Rdata") -->
<!-- ``` -->

<!-- Numeric cleanup finished 170920 -->

<!-- \newpage -->

<!-- # lecsekkolni P és Cu Oberückersee! -->

<!-- ### Arendsee -->
<!-- ```{r} -->
<!-- crustacean_clean_long_ar <- filter(cope01_clean_long,  -->
<!--                                    lake == "Arendsee", -->
<!--                                    Count > 0,  -->
<!--                                    crustacean == TRUE, -->
<!--                                    date_trusted == "yes") -->

<!-- min_date_trusted_ar <- filter(inter, lake == "Arendsee", date_trusted == "yes") %>% -->
<!--   select(date_final) %>% -->
<!--   {min(.)} -->

<!-- g_crustacean_ar <- ggplot(crustacean_clean_long_ar, -->
<!--                           aes(x = date_final,  -->
<!--                               y = Count, -->
<!--                               group = otu_name)) + -->
<!--   geom_point(aes(colour=otu_name, size = best_id_cope01))+ -->
<!--   geom_line(aes(colour=otu_name)) +  -->
<!--   scale_y_log10() + -->
<!--   xlim(1850, 2016) +  -->
<!--   theme(legend.position="none") + -->
<!--   facet_wrap(nrow = 2, ~sci_name) + -->
<!--   ggtitle("Arendsee") -->

<!-- g_crustacean_ar +  -->
<!--   geom_vline(xintercept = min_date_trusted_ar) -->
<!-- ``` -->

<!-- ### Breiter Luzin -->
<!-- ```{r} -->
<!-- crustacean_clean_long_bl <- filter(cope01_clean_long,  -->
<!--                                    lake == "Breiter Luzin", -->
<!--                                    Count > 0,  -->
<!--                                    crustacean == TRUE, -->
<!--                                    date_trusted == "yes") -->

<!-- min_date_trusted_bl <- filter(inter, lake == "Arendsee", date_trusted == "yes") %>% -->
<!--   select(date_final) %>% -->
<!--   {min(.)} -->

<!-- g_crustacean_bl <- ggplot(crustacean_clean_long_bl, -->
<!--                           aes(x = date_final,  -->
<!--                               y = Count, -->
<!--                               group = otu_name)) + -->
<!--   geom_point(aes(colour=otu_name, size = best_id_cope01))+ -->
<!--   geom_line(aes(colour=otu_name)) +  -->
<!--   scale_y_log10() + -->
<!--   xlim(1850, 2016) +  -->
<!--   theme(legend.position="none") + -->
<!--   facet_wrap(nrow = 2, ~sci_name) + -->
<!--   ggtitle("Breiter Luzin") -->

<!-- g_crustacean_bl +  -->
<!--   geom_vline(xintercept = min_date_trusted_bl) -->
<!-- ``` -->





<!-- Plots of OTUs by scientific names -->

<!-- ```{r} -->

<!-- ``` -->



<!-- # Innen -->
<!-- III -->
<!-- VVV -->

<!-- Diana scripts -->
<!-- - assigned OTU plots against age -->



















<!-- # Metadata for replicates -->

<!-- ```{r} -->
<!-- meta_replicate <- data.frame(core = sapply(as.character(names(cope01_clean)), -->
<!--                                            function(x)strsplit(x,"\\.")[[1]][1]), -->
<!--                              depth = sapply(as.character(names(cope01_clean)), -->
<!--                                             function(x)strsplit(x,"\\.")[[1]][2]), -->
<!--                              repli_code = sapply(as.character(names(cope01_clean)), -->
<!--                                                  function(x)strsplit(x,"_")[[1]][2])) -->

<!-- head(meta_replicate) -->
<!-- ``` -->

<!-- There was two WM1_250 samples.  -->
<!-- ```{r} -->
<!-- index_250A <- grep("250A", meta_replicate$depth) -->
<!-- index_250B <- grep("250B", meta_replicate$depth) -->
<!-- index_250AB <- c(grep("250A", meta_replicate$depth), -->
<!--                 grep("250B", meta_replicate$depth)) -->
<!-- ``` -->

<!-- For now just repair the depths for these duplicate WM1_250 samples. The names still distinguish them, -->
<!-- ```{r} -->
<!-- meta_replicate$depth[index_250AB] <-  -->
<!--   gsub("250A", "250", meta_replicate$depth[index_250AB]) -->
<!-- meta_replicate$depth[index_250AB] <-  -->
<!--   gsub("250B", "250", meta_replicate$depth[index_250AB]) -->

<!-- meta_replicate[index_250AB,] -->
<!-- ``` -->

<!-- Correct the depth -->
<!-- ```{r} -->
<!-- meta_replicate$depth <- as.numeric(sapply(as.character(meta_replicate$depth),  -->
<!--                                           function(x)strsplit(x,"_")[[1]][1])) -->

<!-- head(meta_replicate) -->
<!-- ``` -->





<!-- # LVM to identify replicate outliers -->
<!-- ## I feel now this is a bit of an overkill, with lots of error possibilities  -->

<!-- Define very rare species - singletons and doubleton OTUs. boral does not cope well with them and they are not informative about community structure. -->
<!-- ```{r} -->
<!-- index_boral_OTU <- specnumber(cope01_clean) > 2 -->
<!-- cope01_boral <- cope01_clean[index_boral_OTU,] -->
<!-- ``` -->

<!-- Replicates with no OTUs left -->
<!-- ```{r} -->
<!-- index_boral_replicate <- specnumber(t(cope01_boral)) > 0 -->
<!-- cope01_boral <- cope01_boral[,index_boral_replicate] -->
<!-- cope01_boral <- data.frame(t(cope01_boral)) -->
<!-- ``` -->

<!-- Estimate overdispersion parameters with manyglm -->
<!-- ```{r} -->
<!-- cope01_mvabund <- mvabund(cope01_boral) -->
<!-- cope01_manyglm <- manyglm(cope01_mvabund ~ 1, family = "negative.binomial") -->
<!-- ``` -->

<!-- Distribution of the overdispersion parameters -->
<!-- ```{r} -->
<!-- hist(cope01_manyglm$theta) -->
<!-- ``` -->

<!-- Set overdispersion prior -->
<!-- ```{r} -->
<!-- set.prior = list(type = c("normal","normal","normal","uniform"), -->
<!--                  hypparams = c(100, 20, 100, 1)) -->
<!-- ``` -->

<!-- boral is run on the server. Takes long. This run was ready: 170727 -->
<!-- ```{r} -->
<!-- save(file="cope01_boral_replicate_tomodel.RData", cope01_boral) -->

<!-- # load("cope01_boral_replicate_tomodel.RData") -->
<!-- # cope01_boral_replicate <- boral(cope01_boral, -->
<!-- #                                 family = "negative.binomial", -->
<!-- #                                 prior.control = set.prior, -->
<!-- #                                 num.lv = 2, n.burnin = 10000, -->
<!-- #                                 n.iteration = 40000, n.thin = 30) -->
<!-- # save(cope01_boral_replicate, file="cope01_boral_replicate_modelled_40000-iter.RData") -->

<!-- load("cope01_boral_replicate_modelled_40000-iter.RData") -->
<!-- ``` -->

<!-- Check the model -->
<!-- ```{r eval = F} -->
<!-- # par(mfrow = c(2,2)) -->
<!-- # plot(cope01_boral_replicate) -->
<!-- ``` -->

<!-- Calculate replicate centroids. Ideas from here: -->
<!-- https://stackoverflow.com/questions/23463324/r-add-centroids-to-scatter-plot -->
<!-- ```{r} -->
<!-- cope01_replicate_coordinates <- data.frame(cope01_boral_replicate$lv.median) -->

<!-- # create a dataframe for calculating centroids for each sample -->
<!-- cope01_for_centroids <-  -->
<!--   data.frame(cope01_replicate_coordinates,  -->
<!--              sample = sapply(as.character( -->
<!--                rownames(cope01_replicate_coordinates)), -->
<!--                function(x)strsplit(x,"_")[[1]][1])) -->

<!-- # re-order df alphabetically according to the replicate -->
<!-- cope01_for_centroids <- cope01_for_centroids[ -->
<!--   order(cope01_for_centroids$sample),] -->
<!-- ``` -->

<!-- Calculate centroid coordinates -->
<!-- ```{r} -->
<!-- cope01_replicate_centroids <- aggregate(cbind(lv1, lv2) ~ sample, -->
<!--                                         cope01_for_centroids, -->
<!--                                         mean) -->
<!-- ``` -->

<!-- Check them on one lake. -->
<!-- ```{r message=F} -->
<!-- # metadata -->
<!-- meta_boral <- meta_replicate[rownames(meta_replicate) %in% rownames(cope01_boral),] -->
<!-- meta_boral <- data.frame(meta_boral,  -->
<!--                          sample = sapply(as.character( -->
<!--                            rownames(meta_boral)), -->
<!--                            function(x)strsplit(x,"_")[[1]][1])) -->

<!-- # ordination -->
<!-- par(mfrow = c(1,1), mar = c(4.5,4.5,2,1)) -->
<!-- cope01_ord_AR1 = ordiplot(cope01_boral_replicate$lv.median[ -->
<!--   meta_boral$core == "AR1",],  -->
<!--   choices = c(1,2), type = "none", -->
<!--   display = "sites", -->
<!--   cex.axis = 1.3, cex.lab = 1.3, -->
<!--   main = "cope01 communities, AR",                       -->
<!--   xlab = "Community axis 1", ylab = "Community axis 2") -->
<!-- points(cope01_boral_replicate$lv.median[meta_boral$core == "AR1",], -->
<!--        col=as.numeric(meta_boral$sample[meta_boral$core == "AR1"]), -->
<!--        pch=19) -->
<!-- points(cope01_replicate_centroids[grep("AR1",cope01_replicate_centroids$sample), -->
<!--                                   c(2,3)], pch = "+", col = as.numeric( -->
<!--                                     cope01_replicate_centroids$sample)) -->
<!-- ordispider(cope01_ord_AR1, meta_boral$sample[meta_boral$core == "AR1"], -->
<!--            col=as.numeric(cope01_replicate_centroids$sample)) -->
<!-- ordisurf(cope01_ord_AR1, meta_boral$depth[meta_boral$core == "AR1"],  -->
<!--          add = T) -->
<!-- ``` -->
<!-- \newpage -->

<!-- 170906 -->

<!-- Merge replicate and centroid coordinates  -->
<!-- ```{r} -->
<!-- cope01_replicate_coordinates_centroids <-  -->
<!--   merge(cope01_for_centroids, -->
<!--         cope01_replicate_centroids, -->
<!--         by = "sample") -->
<!-- rownames(cope01_replicate_coordinates_centroids) <- -->
<!--   rownames(cope01_for_centroids) -->
<!-- ``` -->

<!-- Select the outlier replicates:  -->
<!-- they are at least n times further away from their pond centroid -->
<!-- than the median distance of all replicates. -->


<!-- Calculate the median distances -->
<!-- ```{r} -->
<!-- cope01_replicate_centroid_distances <- c() -->
<!-- for (i in rownames(cope01_replicate_coordinates_centroids)) { -->
<!--   single_distance <- -->
<!--     sqrt((cope01_replicate_coordinates_centroids[i,"lv1.x"] - -->
<!--             cope01_replicate_coordinates_centroids[i,"lv1.y"])^2 + -->
<!--            (cope01_replicate_coordinates_centroids[i,"lv2.x"] - -->
<!--               cope01_replicate_coordinates_centroids[i,"lv2.y"])^2) -->
<!--   cope01_replicate_centroid_distances <- -->
<!--     rbind(cope01_replicate_centroid_distances,  -->
<!--           single_distance) -->
<!-- } -->
<!-- ``` -->


<!-- Bind the distances to the coordinate file -->
<!-- ```{r} -->
<!-- cope01_replicate_coordinates_centroids <- -->
<!--   cbind(cope01_replicate_coordinates_centroids, -->
<!--         distance = cope01_replicate_centroid_distances) -->
<!-- ``` -->

<!-- Median distances for of replicates from group centroids -->
<!-- ```{r} -->
<!-- cope01_distance_centroids <-  -->
<!--   aggregate(distance ~ sample, -->
<!--             cope01_replicate_coordinates_centroids, -->
<!--             median) -->

<!-- ``` -->


<!-- Bind the distances to the coordinates object -->
<!-- ```{r} -->
<!-- cope01_replicate_coordinates_centroids <-  -->
<!--   merge(cope01_distance_centroids,  -->
<!--         cope01_replicate_coordinates_centroids, -->
<!--         by = "sample") -->

<!-- rownames(cope01_replicate_coordinates_centroids) <- -->
<!--   rownames(cope01_for_centroids) -->
<!-- ``` -->

<!-- Add core name to coordinate object -->
<!-- ```{r} -->
<!-- cope01_replicate_coordinates_centroids <- -->
<!--   data.frame(cope01_replicate_coordinates_centroids, -->
<!--              core = sapply(as.character( -->
<!--                cope01_replicate_coordinates_centroids$sample), -->
<!--                function(x)strsplit(x,"\\.")[[1]][1])) -->
<!-- ``` -->














<!-- Plot the ordination with the replicates that were used in boral. -->
<!-- ```{r, message=F} -->
<!-- meta_boral <- meta_replicate[rownames(meta_replicate) %in%  -->
<!--                                rownames(cope01_boral),] -->

<!-- par(mfrow = c(1,1), mar = c(4.5,4.5,2,1)) -->
<!-- cope01_ord = ordiplot(cope01_boral_replicate$lv.median,  -->
<!--                       choices = c(1,2), type = "none", -->
<!--                       display = "sites", -->
<!--                       cex.axis = 1.3, cex.lab = 1.3, -->
<!--                       main = "cope01 communities, 10 lakes", -->
<!--                       xlab = "Community axis 1", ylab = "Community axis 2") -->
<!-- points(cope01_boral_replicate$lv.median, -->
<!--          col=as.numeric(meta_boral$repli_code) + 100, -->
<!--          pch=19, cex=0.7) -->
<!-- ordisurf(cope01_ord, meta_boral$depth, -->
<!--          add=T, col = "red", cex = 1.3) -->
<!-- ``` -->
